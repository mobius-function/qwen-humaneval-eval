# HumanEval Evaluation Configuration
# This file defines all experiment configurations for running inference and evaluation

# vLLM Server Settings
vllm:
  api_url: "http://localhost:8000/v1"
  max_tokens: 768  # Increased from 512 to allow more complex implementations
  top_p: 0.95
  stop_sequences:
    - "\nclass "
    - "\ndef "
    # REMOVED "\n#" - was too aggressive, stopped generation at inline comments
    - "\nif __name__"

# Inference Settings
inference:
  num_workers: 16  # Parallel API calls (default: 16 for I/O-bound tasks)

# Evaluation Settings
evaluation:
  timeout: 3  # Timeout per test in seconds
  num_workers: null  # null = auto-detect CPU count
  results_dir: "results"

# Dataset Settings
dataset:
  max_samples: null  # null = run on all 164 problems

# Experiment Configurations
# Each experiment defines a unique combination of prompt strategy and settings
experiments:
  - name: "infilling_none"
    description: "Code infilling with TODO markers (no post-processing)"
    enabled: false
    prompt_strategy: "infilling"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_infilling_none.jsonl"
    results_file: "evaluation_infilling_none.json"

  - name: "minimal_none"
    description: "Minimal prompt (no post-processing)"
    enabled: true
    prompt_strategy: "minimal"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_minimal_none.jsonl"
    results_file: "evaluation_minimal_none.json"

  - name: "instructional_none"
    description: "Instructional prompt emphasizing correctness"
    enabled: false
    prompt_strategy: "instructional"
    postprocess_strategy: "none"
    temperature: 0.1
    output_file: "completions_instructional_none.jsonl"
    results_file: "evaluation_instructional_none.json"

  - name: "fewshot_none"
    description: "Few-shot prompt with example"
    enabled: false
    prompt_strategy: "fewshot"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_fewshot_none.jsonl"
    results_file: "evaluation_fewshot_none.json"

  - name: "cot_none"
    description: "Chain of thought reasoning prompt"
    enabled: false
    prompt_strategy: "cot"
    postprocess_strategy: "none"
    temperature: 0.3
    output_file: "completions_cot_none.jsonl"
    results_file: "evaluation_cot_none.json"

  - name: "datadriven_none"
    description: "Data-driven prompt based on analysis of all 164 problems"
    enabled: false
    prompt_strategy: "datadriven"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_datadriven_none.jsonl"
    results_file: "evaluation_datadriven_none.json"

  - name: "expert_none"
    description: "Expert-engineered prompt with self-review, persona, edge cases"
    enabled: false
    prompt_strategy: "expert"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_expert_none.jsonl"
    results_file: "evaluation_expert_none.json"

  - name: "helper_none"
    description: "Helper prompt with code patterns"
    enabled: false
    prompt_strategy: "helper"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_helper_none.jsonl"
    results_file: "evaluation_helper_none.json"

  - name: "optimized_v1_none"
    description: "Optimized prompt v1"
    enabled: false
    prompt_strategy: "optimized_v1"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_optimized_v1_none.jsonl"
    results_file: "evaluation_optimized_v1_none.json"

  - name: "optimized_v2_none"
    description: "Optimized prompt v2"
    enabled: false
    prompt_strategy: "optimized_v2"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_optimized_v2_none.jsonl"
    results_file: "evaluation_optimized_v2_none.json"

  - name: "optimized_v3_none"
    description: "Optimized prompt v3"
    enabled: false
    prompt_strategy: "optimized_v3"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_optimized_v3_none.jsonl"
    results_file: "evaluation_optimized_v3_none.json"

  - name: "opt1_none"
    description: "Category-based prompt with targeted guidance per problem type"
    enabled: false
    prompt_strategy: "opt1"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_opt1_none.jsonl"
    results_file: "evaluation_opt1_none.json"

  - name: "try1_none"
    description: "Minimal prompt v2 with anti-stub instruction (try1)"
    enabled: true
    prompt_strategy: "try1"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_try1_none.jsonl"
    results_file: "evaluation_try1_none.json"

  - name: "minimal_v2_none"
    description: "Minimal prompt with 'return' starter hint"
    enabled: true
    prompt_strategy: "minimal_v2"
    postprocess_strategy: "none"
    temperature: 0.2
    output_file: "completions_minimal_v2_none.jsonl"
    results_file: "evaluation_minimal_v2_none.json"
